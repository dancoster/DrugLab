{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7r295yf_0FuH"
      },
      "source": [
        "## Mount Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3qFH81LCf_W_",
        "outputId": "1386b1b2-2cf8-4320-b5e6-275bfc9acd08"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ee2ApMjC0Jgh"
      },
      "source": [
        "## Lab test MIMIC Extract Mapping\n",
        "\n",
        "From other file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "N9Bt5eBIGoGx"
      },
      "outputs": [],
      "source": [
        "lab_mapping = {'ALT': {'Alanine aminotransferase': [50861, 769, 220644]},\n",
        " 'ANA': {'Fraction inspired oxygen': [189]},\n",
        " 'AST': {'Asparate aminotransferase': [50878, 770, 220587]},\n",
        " 'Hemoglobin': {'Hemoglobin percent': [50852],\n",
        "  'Hemoglobin C': [51224],\n",
        "  'Hemoglobin F': [51225],\n",
        "  'Hemoglobin A2': [51223],\n",
        "  'Hemoglobin': [814, 220228, 51222, 50811]},\n",
        " 'INR': {'Prothrombin time INR': [51237, 815, 1530, 227467]},\n",
        " 'bilirubin': {'Bilirubin': [51465,\n",
        "   50883,\n",
        "   803,\n",
        "   225651,\n",
        "   50885,\n",
        "   1538,\n",
        "   848,\n",
        "   225690,\n",
        "   50884],\n",
        "#   'Bilirubin, Total, Pleural': [51049],\n",
        "#   'Bilirubin, Total, Body Fluid': [51028],\n",
        "#   'Bilirubin, Total, Ascites': [50838]\n",
        "  },\n",
        " 'calcium': {'Calcium': [786, 1522, 3746, 51029, 50893, 225625],\n",
        "  'Calcium ionized': [50808, 816, 225667, 3766],\n",
        "#   'Calcium urine': [51066, 51077]\n",
        "  },\n",
        " 'creatinine': {'Creatinine': [791, 1525, 220615, 50912],\n",
        "  'Creatinine ascites': [50841],\n",
        "#   'Creatinine body fluid': [51032],\n",
        "#   'Creatinine pleural': [51052],\n",
        "#   'Creatinine urine': [51082]\n",
        "},\n",
        " 'glucose': {'Glucose': [50931,\n",
        "   807,\n",
        "   811,\n",
        "   1529,\n",
        "   50809,\n",
        "   3745,\n",
        "   225664,\n",
        "   220621,\n",
        "   226537],\n",
        "#   'Glucose urine': [51478],\n",
        "#   'Glucose, CSF': [51014],\n",
        "#   'Estimated Actual Glucose': [51529],\n",
        "#   'Glucose, Urine': [51084],\n",
        "#   'Glucose, Pleural': [51053],\n",
        "#   'Glucose, Joint Fluid': [51022],\n",
        "#   'Glucose, Ascites': [50842],\n",
        "#   'Glucose, Body Fluid': [51034]\n",
        "},\n",
        " 'lactic acid': {'Lactic acid': [818, 225668, 1531]},\n",
        " 'magnesium': {'Magnesium': [50960], 'Magnesium, Urine': [51088]},\n",
        " 'platelets': {'Platelets': [51265, 828, 227457], 'Large Platelets': [51240]},\n",
        " 'potassium': {'Potassium': [829, 1535, 227464, 50971, 50822],\n",
        "#   'Potassium serum': [227442],\n",
        "#   'Potassium, Body Fluid': [51041],\n",
        "#   'Potassium, Pleural': [51057],\n",
        "#   'Potassium, Stool': [51064],\n",
        "#   'Potassium, Urine': [51097],\n",
        "#   'Potassium, Ascites': [50847]\n",
        "  },\n",
        " 'sodium': {'Sodium': [837, 1536, 220645, 226534, 50983, 50824],\n",
        "#   'Sodium, Ascites': [50848],\n",
        "#   'Sodium, Body Fluid': [51042],\n",
        "#   'Sodium, Pleural': [51058],\n",
        "#   'Sodium, Stool': [51065],\n",
        "#   'Sodium, Urine': [51100]\n",
        "  },\n",
        " 'Uric acid': {'Uric Acid': [51007], 'Uric Acid, Urine': [51105]},\n",
        " 'B12': {'Vitamin B12': [51010]},\n",
        " 'prolactin': {'Prolactin': [50973]},\n",
        " 'Amylase': {'Amylase': [50867], \n",
        "#  'Amylase, Ascites': [50836], 'Amylase, Body Fluid': [51026],'Amylase, Joint Fluid': [51020],'Amylase, Pleural': [51047], 'Amylase, Urine': [51072]\n",
        " },\n",
        " 'Lipase': {'Lipase': [50956], \n",
        "#  'Lipase, Ascites': [50844], 'Lipase, Body Fluid': [51036]\n",
        " },\n",
        " 'Aptt': {'PTT': [825, 1533, 227466, 51275]}}\n",
        "lab_mapping['Hematocrit']  = {\n",
        "    'Hematocrit' : [813, 220545, 51221, 50810]\n",
        "}\n",
        "lab_mapping['Red blood cell'] = {\n",
        "    'Red blood cell': [51279, 833]\n",
        "}\n",
        "lab_mapping['Albumin'] = {\n",
        "    'Albumin': [50862, 772, 1521, 227456]\n",
        "}\n",
        "lab_mapping['Magnesium'] = {\n",
        "    'Magnesium': [821, 1532, 220635, 50960]\n",
        "}\n",
        "lab_mapping[\"CPK\"] = {\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nucWUbS90NnO"
      },
      "source": [
        "## Source Code for Plotting and Querying data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "from abc import ABC, abstractmethod\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.patches import Rectangle\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import os\n",
        "from scipy.stats import pearsonr, spearmanr\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "-D9Nel7R79lS"
      },
      "outputs": [],
      "source": [
        "# Util Functions\n",
        "\n",
        "def sort_rows_with_time(p_corrs, s_corrs, after_windows):\n",
        "    s_p = sorted([k for k in zip(p_corrs, after_windows)], key=lambda k: k[1][0])\n",
        "    p_corrs = [k[0][0] for k in s_p]\n",
        "    after_windows1 = [str(k[1]) for k in s_p]\n",
        "    s_s = sorted([k for k in zip(s_corrs, after_windows)], key=lambda k: k[1][0])\n",
        "    s_corrs = [k[0][0] for k in s_s]\n",
        "    after_windows2 = [str(k[1]) for k in s_p]\n",
        "    return p_corrs, s_corrs, after_windows1, after_windows2\n",
        "\n",
        "def plot_corrs(corrs, after_windows, after_windows_map, ax, title='', plot_name='',  after_window_info=None):\n",
        "\n",
        "    p_corrs = [c[0] for c in corrs]\n",
        "    s_corrs = [c[1] for c in corrs]\n",
        "    final_plot_name = f'{plot_name}_{title}'\n",
        "    after_windows = [after_windows_map[a.split(\"_\")[-2]] for a in after_windows]\n",
        "    \n",
        "    p_corrs, s_corrs, after_windows1, after_windows2 = sort_rows_with_time(p_corrs, s_corrs, after_windows)\n",
        "\n",
        "    ax[0].plot(after_windows1, p_corrs, '-o')\n",
        "    ax[0].set_title(f'{final_plot_name} Pearsons Corr')\n",
        "    ax[0].set(xlabel='Time (h)', ylabel='Correlation')\n",
        "    ax[0].set_xticks(after_windows1)\n",
        "    ax[0].grid()\n",
        "\n",
        "    ax[1].plot(after_windows2, s_corrs, '-o')\n",
        "    ax[1].set_title(f'{final_plot_name} Spearmans Corr')\n",
        "    ax[1].set(xlabel='Time (h)', ylabel='Correlation')\n",
        "    ax[1].set_xticks(after_windows2)\n",
        "    ax[1].grid()\n",
        "    \n",
        "\n",
        "def plot_func(lab, presc, d, dirname, plot_dir, plot_dir1, window=(1,24), title='', unit='', labels=None, plot_name='', ax=None):    \n",
        "    plot_data = d\n",
        "    if ax is None:\n",
        "        sns.regplot(x = \"time\", \n",
        "                y = 'data', \n",
        "                data = plot_data.sort_values([\"time\"]), \n",
        "                truncate=False)\n",
        "        n = plot_data.shape[0]\n",
        "        plt.title(lab+'<>'+presc+'- '+ title+ ' \\nchange in lab measurment and time taken for change')\n",
        "        plt.xlabel('Time (h)')\n",
        "        plt.ylabel(f\"{title} change in {lab} lab measurment ({unit})\")\n",
        "        if labels is not None:\n",
        "            extra = Rectangle((0, 0), 1, 1, fc=\"w\", fill=False, edgecolor='none', linewidth=0)\n",
        "            plt.legend([extra for i in range(5)], (f'Pearson Correlation = {round(labels[0][0], 4)}', f'Pearson Correlation p-value = {round(labels[0][1], 4)}', f'Spearmans Correlation = {round(labels[1][0], 4)}', f'Spearmans Correlation p-value = {round(labels[1][1], 4)}', f'Number of data points = {n}'))\n",
        "        if not os.path.isdir(os.path.join(plot_dir1, f\"{lab}<>{presc}\")):\n",
        "            os.mkdir(os.path.join(plot_dir1, f\"{lab}<>{presc}\"))\n",
        "        if dirname is None or dirname == \"\":\n",
        "            plt.savefig(os.path.join(plot_dir1, f\"{lab}<>{presc}\", plot_name+\".png\"))\n",
        "        else:\n",
        "            if not os.path.isdir(os.path.join(plot_dir1, f\"{lab}<>{presc}\", dirname)):\n",
        "                os.mkdir(os.path.join(plot_dir1, f\"{lab}<>{presc}\", dirname))\n",
        "            plt.savefig(os.path.join(plot_dir1, f\"{lab}<>{presc}\", dirname, plot_name+\".png\"))\n",
        "        plt.clf()\n",
        "    \n",
        "    else:\n",
        "        sns.regplot(\n",
        "                ax=ax,\n",
        "                x = \"time\", \n",
        "                y = 'data', \n",
        "                data = plot_data.sort_values([\"time\"]), \n",
        "                truncate=False)\n",
        "        n = plot_data.shape[0]\n",
        "        ax.set_title(lab+'<>'+presc+'- '+ title+ ' \\nchange in lab measurment and time taken for change')\n",
        "        ax.set(xlabel='Time (h)', ylabel=f\"{title} change in {lab} lab measurment ({unit})\")\n",
        "        ax.grid()\n",
        "        if labels is not None:\n",
        "            extra = Rectangle((0, 0), 1, 1, fc=\"w\", fill=False, edgecolor='none', linewidth=0)\n",
        "            ax.legend([extra for i in range(5)], (f'Pearson Correlation = {round(labels[0][0], 4)}', f'Pearson Correlation p-value = {round(labels[0][1], 4)}', f'Spearmans Correlation = {round(labels[1][0], 4)}', f'Spearmans Correlation p-value = {round(labels[1][1], 4)}', f'Number of data points = {n}'))\n",
        "\n",
        "def remove_outlier(val, time_diff):\n",
        "    val = pd.DataFrame(val)\n",
        "    time_diff = pd.DataFrame(time_diff)\n",
        "    \n",
        "    # IQR\n",
        "    Q1 = np.percentile(val, 25, method = 'midpoint')        \n",
        "    Q3 = np.percentile(val, 75, method = 'midpoint')\n",
        "    IQR = Q3 - Q1        \n",
        "    \n",
        "    # Upper bound\n",
        "    upper = np.where(val >= (Q3+1.5*IQR))\n",
        "    # Lower bound\n",
        "    lower = np.where(val <= (Q1-1.5*IQR))\n",
        "\n",
        "    # Filtering\n",
        "    if len(upper) > 0:\n",
        "        val.drop(upper[0], inplace = True)\n",
        "        time_diff.drop(upper[0], inplace = True)\n",
        "    if len(lower) > 0:\n",
        "        val.drop(lower[0], inplace = True)\n",
        "        time_diff.drop(lower[0], inplace = True)\n",
        "    return val, time_diff\n",
        "\n",
        "def check_med2(row):\n",
        "    if row[\"HADM_ID\"] in t_med2[\"HADM_ID\"].to_list():\n",
        "        if row[\"ITEMID\"] in t_med2[t_med2[\"HADM_ID\"]==row[\"HADM_ID\"]][\"ITEMID\"].to_list():\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "def get_med2(row):\n",
        "    temp = t_med2[t_med2[\"HADM_ID\"]==row[\"HADM_ID\"]] \n",
        "    return temp[temp[\"ITEMID\"]==row[\"ITEMID\"]].iloc[0]\n",
        "from sklearn import datasets, linear_model, metrics\n",
        "\n",
        "def get_normalized_trend(data):\n",
        "    selected = data[['VALUENUM', 'hours_from_med']]\n",
        "    if selected.shape[0]<2:\n",
        "        return float(\"NaN\")\n",
        "    reg = linear_model.LinearRegression()\n",
        "    reg.fit(np.array(data['hours_from_med']).reshape(-1,1), np.array(data['VALUENUM']).reshape(-1,1))\n",
        "    return reg.coef_[0][0]\n",
        "\n",
        "def get_normalized_trend_np(data):\n",
        "    selected = data[['VALUENUM', 'hours_in']]\n",
        "    print(selected)\n",
        "    if selected.shape[0]<2:\n",
        "        return float(\"NaN\")\n",
        "    print(np.array(data['hours_from_med']), np.array(data['VALUENUM']))\n",
        "    t = np.polyfit(np.array(data['hours_from_med']), np.array(data['VALUENUM']), 1,full=True)\n",
        "    coefficients, residuals, _, _, _ = t\n",
        "    print(t)\n",
        "    mse = residuals[0]/(len(selected.index))\n",
        "    nrmse = np.sqrt(mse)/(selected.max() - selected.min())\n",
        "    return 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "nf2HLNOrfKuw"
      },
      "outputs": [],
      "source": [
        "# Utils class\n",
        "class AnalysisUtils:\n",
        "\n",
        "    def __init__(self, data, res, gender=\"MF\", age_b=0, age_a=100, ethnicity=\"WHITE\", lab_mapping=None, load=True):\n",
        "        '''\n",
        "        Params\n",
        "        data : path to dataset\n",
        "        res : path to result output files\n",
        "        gender : stratification param for gender\n",
        "        age_b : stratification param for start of age group\n",
        "        age_a : stratification param for end of age group\n",
        "        ethnicity : stratification param for ethnicity\n",
        "        lab_mapping : lab test mapping from mimic extract. Loaded externally and used in the class \n",
        "        '''\n",
        "        self.data = data \n",
        "        self.res = res\n",
        "        self.gender = gender\n",
        "        self.age_b = age_b\n",
        "        self.age_a = age_a\n",
        "        self.ethnicity = ethnicity\n",
        "        self.stratify_prefix = f\"{age_b}-{age_a}_{gender}_{ethnicity}\"\n",
        "\n",
        "        self.res_dict_mapping_med = None\n",
        "        self.d_m_l_doc = None\n",
        "        if load:\n",
        "            self.load_mappings()\n",
        "        self.lab_mapping = lab_mapping\n",
        "\n",
        "    def load_mappings(self):\n",
        "        \"\"\"\n",
        "        Load Medication and Lab test name mappings from MIMIC Extract and Clinically Validated sources\n",
        "        \"\"\"\n",
        "        self.d_m_l_doc = pd.read_csv(os.path.join(self.data, \"mimiciii\", \"1.4\",\"preprocessed\", \"mapping_med_itemid_doc.csv\")).drop(columns=[\"Unnamed: 0\"])\n",
        "        dict_d_m_l = self.d_m_l_doc.to_dict(\"records\")\n",
        "        self.res_dict_mapping_med = {\n",
        "            v:k[\"Medication\"] for k in dict_d_m_l for v in [int(id) for id in k[\"ITEMID_with_manual\"][1:-1].split(\",\") if id != '']\n",
        "        }\n",
        "\n",
        "    def generate_med_lab_pairs(self):\n",
        "        \"\"\"\n",
        "        Generate medication and lab test pair names.\n",
        "        \"\"\"\n",
        "        \n",
        "        d_lab_map = {k:list(v.keys()) for k, v in self.lab_mapping.items()}\n",
        "        indexes = list(self.d_m_l_doc.groupby([\"Medication\", \"lab result\"]).count().index)\n",
        "\n",
        "        med_vals = [k[0].strip() for k in indexes]\n",
        "        labtest_vals = [k[1].strip() for k in indexes]\n",
        "        med_vals.append('Insulin - Regular')\n",
        "        labtest_vals.append('glucose')\n",
        "\n",
        "        med_vals.append('Packed Red Blood Cells')\n",
        "        labtest_vals.append('Hemoglobin')\n",
        "\n",
        "        med_vals.append('Calcium Gluconate (CRRT)')\n",
        "        labtest_vals.append('calcium')\n",
        "\n",
        "        med_vals.append('Packed Red Blood Cells')\n",
        "        labtest_vals.append('Red blood cell')\n",
        "\n",
        "        med_vals.append('Packed Red Blood Cells')\n",
        "        labtest_vals.append('Hematocrit')\n",
        "\n",
        "        med_vals.append('Albumin')\n",
        "        labtest_vals.append('Albumin')\n",
        "\n",
        "        med_vals.append('Albumin')\n",
        "        labtest_vals.append('Hematocrit')\n",
        "\n",
        "        med_vals.append('Albumin 5%')\n",
        "        labtest_vals.append('Albumin')\n",
        "\n",
        "        med_vals.append('Albumin 5%')\n",
        "        labtest_vals.append('Hematocrit')\n",
        "\n",
        "        med_vals.append('Albumin 25%')\n",
        "        labtest_vals.append('Albumin')\n",
        "\n",
        "        med_vals.append('Albumin 25%')\n",
        "        labtest_vals.append('Hematocrit')\n",
        "\n",
        "        med_vals.append('Magnesium Sulfate')\n",
        "        labtest_vals.append('Magnesium')\n",
        "        l_med_lab = [(i[0], k) for i in zip(med_vals, labtest_vals) for k in d_lab_map[i[1]]]\n",
        "        labtest_vals_new = [k[1] for k in l_med_lab]\n",
        "        med_vals_new = [k[0] for k in l_med_lab]\n",
        "        return med_vals_new, labtest_vals_new"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "class DatasetParser(ABC):\n",
        "    \"\"\" Interface to define a parser for datasets.\"\"\"\n",
        "\n",
        "    @abstractmethod\n",
        "    def load_med1(self) -> pd.DataFrame:\n",
        "        \"\"\" Load data of 1st medication administration during the 1st admimission of a patient \"\"\"\n",
        "        ...\n",
        "\n",
        "    @abstractmethod\n",
        "    def load_med2(self) -> pd.DataFrame:\n",
        "        \"\"\" Load data of 2nd medication administration during the 1st admimission of a patient \"\"\"\n",
        "        ...\n",
        "\n",
        "    @abstractmethod\n",
        "    def load_lab(self, h_med_adm1: pd.DataFrame, h_med_adm2: pd.DataFrame) -> pd.DataFrame:\n",
        "        \"\"\" Load data on all lab tests taken during the 1st admimission of a patient \"\"\"\n",
        "        ...\n",
        "\n",
        "    @abstractmethod\n",
        "    def parse(self, use_pairs: bool) -> tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
        "        \"\"\" Load med1, med2 and lab test data \"\"\"\n",
        "        ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "class MIMICParser(DatasetParser, AnalysisUtils):\n",
        "    def __init__(self, data, res, gender=\"MF\", age_b=0, age_a=100, ethnicity=\"WHITE\", lab_mapping=None):\n",
        "       AnalysisUtils.__init__(self, data, res, gender=gender, age_b=age_b, age_a=age_a, ethnicity=ethnicity, lab_mapping=lab_mapping)\n",
        "\n",
        "    def load_med1(self):\n",
        "        \"\"\"\n",
        "        Load 1st Medication data\n",
        "        \"\"\"\n",
        "        med1 = pd.read_csv(os.path.join(self.data, \"mimiciii/1.4/preprocessed\", \"med1_vectorized.csv\"))\n",
        "        h_adm_1 = med1.sort_values([\"HADM_ID\", \"STARTTIME\"]).groupby(\"SUBJECT_ID\").nth(0)[\"HADM_ID\"].to_list()\n",
        "        med1 = med1[med1.HADM_ID.isin(h_adm_1)]\n",
        "        med1 = med1.drop(columns=[\"Unnamed: 0\"])\n",
        "        med1 = med1[med1[\"AGE\"]>=self.age_b]\n",
        "        med1 = med1[med1[\"AGE\"]<=self.age_a]\n",
        "        med1 = med1[med1[\"GENDER\"]==self.gender] if self.gender != \"MF\" else med1\n",
        "        med1 = med1[med1[\"ETHNICITY\"]==self.ethnicity]\n",
        "        med1[\"MIMICExtractLabel\"] = med1.apply(lambda r: self.res_dict_mapping_med[r[\"ITEMID\"]] if r[\"ITEMID\"] in self.res_dict_mapping_med else r[\"LABEL\"], axis=1)\n",
        "        med1[\"STARTTIME\"] = pd.to_datetime(med1[\"STARTTIME\"])\n",
        "        med1[\"ENDTIME\"] = pd.to_datetime(med1[\"ENDTIME\"])\n",
        "        med1[\"ADMITTIME\"] = pd.to_datetime(med1[\"ADMITTIME\"])\n",
        "        med1[\"MedTimeFromAdmit\"] = med1[\"ENDTIME\"]-med1[\"ADMITTIME\"]\n",
        "        med1[\"hours_in\"] = med1[\"MedTimeFromAdmit\"].dt.total_seconds()/3600\n",
        "        return med1, h_adm_1\n",
        "    \n",
        "    def load_med2(self):\n",
        "        \"\"\"\n",
        "        Load 2nd Medication data\n",
        "        \"\"\"\n",
        "        med2 = pd.read_csv(os.path.join(self.data, \"mimiciii/1.4/preprocessed\", \"med2_vectorized.csv\"))\n",
        "        h_adm_2 = med2.sort_values([\"SUBJECT_ID\", \"STARTTIME\"]).groupby(\"SUBJECT_ID\").nth(0)[\"HADM_ID\"].to_list()\n",
        "        med2 = med2.drop(columns=[\"Unnamed: 0\"])\n",
        "        med2 = med2[med2[\"AGE\"]>=self.age_b]\n",
        "        med2 = med2[med2[\"AGE\"]<=self.age_a]\n",
        "        med2 = med2[med2[\"GENDER\"]==self.gender] if self.gender != \"MF\" else med2\n",
        "        med2 = med2[med2[\"ETHNICITY\"]==self.ethnicity]\n",
        "        med2[\"MIMICExtractLabel\"] = med2.apply(lambda r: self.res_dict_mapping_med[r[\"ITEMID\"]] if r[\"ITEMID\"] in self.res_dict_mapping_med else r[\"LABEL\"], axis=1)\n",
        "        med2[\"STARTTIME\"] = pd.to_datetime(med2[\"STARTTIME\"])\n",
        "        med2[\"ENDTIME\"] = pd.to_datetime(med2[\"ENDTIME\"])\n",
        "        med2[\"ADMITTIME\"] = pd.to_datetime(med2[\"ADMITTIME\"])\n",
        "        med2[\"MedTimeFromAdmit\"] = med2[\"ENDTIME\"]-med2[\"ADMITTIME\"]\n",
        "        return med2, h_adm_2\n",
        "\n",
        "    def load_lab(self, h_med_adm1, h_med_adm2):\n",
        "        \"\"\"\n",
        "        Load lab test data from LABEVENTS and CHARTEVENTS tables\n",
        "        \"\"\"\n",
        "        labs = pd.read_csv(os.path.join(self.data, \"mimiciii/1.4/preprocessed\", \"lab_patient_data_mimic_extract_2.csv\"))\n",
        "        t = labs[labs[\"AGE\"]<100]\n",
        "        t = pd.DataFrame(t[\"AGE\"].value_counts()).reset_index().sort_values([\"index\"])\n",
        "        plt.bar(t[\"index\"], t[\"AGE\"])\n",
        "        plt.xlabel('Age')\n",
        "        plt.ylabel('Count of Patients')\n",
        "        plt.title('Distribution of age')\n",
        "        labs = labs.drop(columns=[\"Unnamed: 0\"])\n",
        "        labs = labs[labs.HADM_ID.isin(h_med_adm1+h_med_adm2)]\n",
        "        labs = labs[labs[\"AGE\"]>=self.age_b]\n",
        "        labs = labs[labs[\"AGE\"]<=self.age_a]\n",
        "        labs = labs[labs[\"GENDER\"]==self.gender] if self.gender != \"MF\" else labs\n",
        "        labs = labs[labs[\"ETHNICITY\"]==self.ethnicity]\n",
        "        labs[\"CHARTTIME\"] = pd.to_datetime(labs[\"CHARTTIME\"])\n",
        "        labs[\"ADMITTIME\"] = pd.to_datetime(labs[\"ADMITTIME\"])\n",
        "        labs[\"LabTimeFromAdmit\"] = labs[\"CHARTTIME\"]-labs[\"ADMITTIME\"]\n",
        "        labs[\"hours_in\"] = labs[\"LabTimeFromAdmit\"].dt.total_seconds()/3600\n",
        "        return labs\n",
        "\n",
        "    def parse(self, use_pairs=True):\n",
        "        \"\"\"\n",
        "        Loading medication and lab test. Performing basic preprocessing on data.\n",
        "        \"\"\"\n",
        "        med1, hadm1 = self.load_med1()\n",
        "        med2, hadm2 = self.load_med2()\n",
        "        labs = self.load_lab(hadm1, hadm2)\n",
        "        \n",
        "        t_med1, t_med2, t_labs = med1.copy(), med2.copy(), labs.copy()\n",
        "        if use_pairs:\n",
        "            med_vals_new, labtest_vals_new = self.generate_med_lab_pairs()\n",
        "            t_med1 = med1[med1[\"MIMICExtractLabel\"].isin(med_vals_new)]\n",
        "            t_med2 = med2[med2[\"MIMICExtractLabel\"].isin(med_vals_new)]\n",
        "            t_labs = labs[labs[\"MIMICExtractName\"].isin(labtest_vals_new)]\n",
        "            \n",
        "        t_med1 = t_med1.rename(columns={\"LABEL\":\"OldLabel\", \"ITEMID\":\"OldITEMID\", \"MIMICExtractLabel\":\"ITEMID\"})\n",
        "        t_med2 = t_med2.rename(columns={\"LABEL\":\"OldLabel\", \"ITEMID\":\"OldITEMID\", \"MIMICExtractLabel\":\"ITEMID\"})\n",
        "        t_labs = t_labs.rename(columns={\"LABEL\":\"OldLabel\", \"ITEMID\":\"OldITEMID\", \"MIMICExtractName\":\"ITEMID\"})\n",
        "\n",
        "        return t_med1, t_med2, t_labs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [],
      "source": [
        "class HiRiDParser(DatasetParser, AnalysisUtils):\n",
        "    def __init__(self, data, res, gender=\"MF\", age_b=0, age_a=100):\n",
        "        AnalysisUtils.__init__(self, data=data, res=res, gender=gender, age_b=age_b, age_a=age_a, load=False)\n",
        "        self.load_util_datasets()\n",
        "        self.load_med()\n",
        "\n",
        "    def load_util_datasets(self):\n",
        "        path1 = self.res\n",
        "        self.g_table = pd.read_csv(os.path.join(path1, 'general_table.csv'))\n",
        "        h_var_ref = pd.read_csv(os.path.join(path1, 'hirid_variable_reference.csv'))\n",
        "        self.h_var_ref = h_var_ref.rename(columns={\"ID\":\"variableid\"})\n",
        "\n",
        "        self.h_var_ref_pre = pd.read_csv(os.path.join(path1, 'hirid_variable_reference_preprocessed.csv'))\n",
        "        self.o_var_ref = pd.read_csv(os.path.join(path1, 'ordinal_vars_ref.csv'))\n",
        "\n",
        "    def load_med(self):\n",
        "\n",
        "        pharma_records_paths = [i for iq, i in enumerate(os.walk(os.path.join(self.data, \"pharma_records\"))) if iq==1][0][2]\n",
        "        pharma_records = pd.concat([pd.read_csv(os.path.join(self.data, \"pharma_records\", 'csv', file)) for file in pharma_records_paths])\n",
        "        pharma_records = pharma_records.rename(columns={\"pharmaid\":\"variableid\"})\n",
        "\n",
        "        pharma_records_with_name = pd.merge(pharma_records, self.h_var_ref, on=\"variableid\", how=\"inner\")\n",
        "        pharma_records_with_name = pd.merge(pharma_records_with_name, self.g_table, on=\"patientid\", how=\"inner\")\n",
        "        pharma_records_with_name.givenat = pd.to_datetime(pharma_records_with_name.givenat)\n",
        "        self.pharma_records_with_name = pharma_records_with_name.rename(columns={\n",
        "            \"givenat\":\"STARTTIME\",\n",
        "            \"admissiontime\":\"ADMITTIME\",\n",
        "            \"enteredentryat\":\"ENDTIME\",\n",
        "            \"variableid\":\"ITEMID\",\n",
        "            \"patientid\":\"HADM_ID\",\n",
        "            \"Variable Name\":\"LABEL\",\n",
        "            \"age\":\"AGE\",\n",
        "            \"sex\":\"GENDER\",\n",
        "        })\n",
        "\n",
        "    def load_med1(self):\n",
        "        \"\"\"\n",
        "        Load 1st Medication data\n",
        "        \"\"\"\n",
        "\n",
        "        med1 = self.pharma_records_with_name.sort_values([\"HADM_ID\", \"STARTTIME\"]).groupby([\"HADM_ID\", \"ITEMID\"]).nth(0).reset_index()\n",
        "\n",
        "        # stratification\n",
        "        h_adm_1 = med1[\"HADM_ID\"].to_list()\n",
        "        med1 = med1[med1[\"AGE\"]>=self.age_b]\n",
        "        med1 = med1[med1[\"AGE\"]<=self.age_a]\n",
        "        med1 = med1[med1[\"GENDER\"]==self.gender] if self.gender != \"MF\" else med1\n",
        "\n",
        "        med1[\"STARTTIME\"] = pd.to_datetime(med1[\"STARTTIME\"])\n",
        "        med1[\"ENDTIME\"] = pd.to_datetime(med1[\"ENDTIME\"])\n",
        "        med1[\"ADMITTIME\"] = pd.to_datetime(med1[\"ADMITTIME\"])\n",
        "        med1[\"MedTimeFromAdmit\"] = med1[\"STARTTIME\"]-med1[\"ADMITTIME\"]\n",
        "        med1[\"hours_in\"] = med1[\"MedTimeFromAdmit\"].dt.total_seconds()/3600\n",
        "        self.med1 = med1\n",
        "\n",
        "        return med1, h_adm_1\n",
        "    \n",
        "    def load_med2(self):\n",
        "        \"\"\"\n",
        "        Load 2nd Medication data\n",
        "        \"\"\"\n",
        "        med2 = self.pharma_records_with_name.sort_values([\"HADM_ID\", \"STARTTIME\"]).groupby([\"HADM_ID\", \"ITEMID\"]).nth(1).reset_index()\n",
        "\n",
        "        # stratification\n",
        "        h_adm_2 = med2[\"HADM_ID\"].to_list()\n",
        "        med2 = med2[med2[\"AGE\"]>=self.age_b]\n",
        "        med2 = med2[med2[\"AGE\"]<=self.age_a]\n",
        "        med2 = med2[med2[\"GENDER\"]==self.gender] if self.gender != \"MF\" else med2\n",
        "\n",
        "        med2[\"STARTTIME\"] = pd.to_datetime(med2[\"STARTTIME\"])\n",
        "        med2[\"ENDTIME\"] = pd.to_datetime(med2[\"ENDTIME\"])\n",
        "        med2[\"ADMITTIME\"] = pd.to_datetime(med2[\"ADMITTIME\"])\n",
        "        med2[\"MedTimeFromAdmit\"] = med2[\"STARTTIME\"]-med2[\"ADMITTIME\"]\n",
        "        med2[\"hours_in\"] = med2[\"MedTimeFromAdmit\"].dt.total_seconds()/3600\n",
        "        self.med2 = med2\n",
        "\n",
        "        return med2, h_adm_2\n",
        "    \n",
        "    def read_lab(self, path, adm):\n",
        "        labs = pd.read_csv(path)\n",
        "        labs = labs[labs.patientid.isin(adm)]\n",
        "        return labs\n",
        "\n",
        "    def load_lab(self, h_med_adm1, h_med_adm2, n_parts=50):\n",
        "        \"\"\"\n",
        "        Load lab test data from LABEVENTS and CHARTEVENTS tables\n",
        "        \"\"\"\n",
        "        observation_tables_paths = sorted([i for iq, i in enumerate(os.walk(os.path.join(self.data, \"observation_tables 2\"))) if iq==1][0][2])\n",
        "        observation_tables_part = pd.concat([self.read_lab(os.path.join(self.data, \"observation_tables 2\", 'csv', file), h_med_adm1+h_med_adm2) for file in observation_tables_paths[:n_parts]])\n",
        "\n",
        "        observation_tables_part_with_name = pd.merge(observation_tables_part, self.h_var_ref, on=\"variableid\", how=\"inner\")\n",
        "        observation_tables_part_with_name = pd.merge(observation_tables_part_with_name, self.g_table, on=\"patientid\", how=\"inner\")\n",
        "        observation_tables_part_with_name.datetime = pd.to_datetime(observation_tables_part_with_name.datetime)\n",
        "        observation_tables_part_with_name\n",
        "        observation_tables_part_with_name\n",
        "        observation_tables_part_with_name[\"Variable Name\"].value_counts()\n",
        "        observation_tables_part_with_name = observation_tables_part_with_name.rename(columns={\n",
        "            \"datetime\":\"CHARTTIME\",\n",
        "            \"admissiontime\":\"ADMITTIME\",\n",
        "            \"variableid\":\"ITEMID\",\n",
        "            \"patientid\":\"HADM_ID\",\n",
        "            \"Variable Name\":\"LABEL\",\n",
        "            \"value\":\"VALUENUM\",\n",
        "            \"Unit\":\"VALUEUOM\",\n",
        "            \"age\":\"AGE\",\n",
        "            \"sex\":\"GENDER\"\n",
        "        })\n",
        "        labs = observation_tables_part_with_name.copy()\n",
        "\n",
        "        labs = labs[labs[\"AGE\"]>=self.age_b]\n",
        "        labs = labs[labs[\"AGE\"]<=self.age_a]\n",
        "        labs = labs[labs[\"GENDER\"]==self.gender] if self.gender != \"MF\" else labs\n",
        "        \n",
        "        labs[\"CHARTTIME\"] = pd.to_datetime(labs[\"CHARTTIME\"])\n",
        "        labs[\"ADMITTIME\"] = pd.to_datetime(labs[\"ADMITTIME\"])\n",
        "        labs[\"LabTimeFromAdmit\"] = labs[\"CHARTTIME\"]-labs[\"ADMITTIME\"]\n",
        "        labs[\"hours_in\"] = labs[\"LabTimeFromAdmit\"].dt.total_seconds()/3600\n",
        "        return labs\n",
        "\n",
        "    def parse(self, use_pairs=False):\n",
        "        \"\"\"\n",
        "        Loading medication and lab test. Performing basic preprocessing on data.\n",
        "        \"\"\"\n",
        "        med1, hadm1 = self.load_med1()\n",
        "        med2, hadm2 = self.load_med2()\n",
        "        labs = self.load_lab(hadm1, hadm2)\n",
        "        \n",
        "        t_med1, t_med2, t_labs = med1.copy(), med2.copy(), labs.copy()\n",
        "        if use_pairs:\n",
        "            med_vals_new, labtest_vals_new = self.generate_med_lab_pairs()\n",
        "            t_med1 = med1[med1[\"LABEL\"].isin(med_vals_new)]\n",
        "            t_med2 = med2[med2[\"LABEL\"].isin(med_vals_new)]\n",
        "            t_labs = labs[labs[\"LABEL\"].isin(labtest_vals_new)]\n",
        "            \n",
        "        t_med1 = t_med1.rename(columns={\"ITEMID\":\"OldITEMID\", \"LABEL\":\"ITEMID\"})\n",
        "        t_med2 = t_med2.rename(columns={\"ITEMID\":\"OldITEMID\", \"LABEL\":\"ITEMID\"})\n",
        "        t_labs = t_labs.rename(columns={\"ITEMID\":\"OldITEMID\", \"LABEL\":\"ITEMID\"})\n",
        "\n",
        "        return t_med1, t_med2, t_labs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "class DatasetQuerier(AnalysisUtils):\n",
        "\n",
        "    def __init__(self, data, res, gender=\"MF\", age_b=0, age_a=100, ethnicity=\"WHITE\", lab_mapping=None):\n",
        "        self.final = None\n",
        "        self.temp = None\n",
        "        super().__init__(data, res, gender=gender, age_b=age_b, age_a=age_a, ethnicity=ethnicity, lab_mapping=lab_mapping)\n",
        "    \n",
        "    def check_med2(self, t_med2, row):\n",
        "        \"\"\"\n",
        "        Check if a 2nd medication was administered to patients\n",
        "        \"\"\"\n",
        "        if row[\"HADM_ID\"] in t_med2[\"HADM_ID\"].to_list():\n",
        "            if row[\"ITEMID\"] in t_med2[t_med2[\"HADM_ID\"]==row[\"HADM_ID\"]][\"ITEMID\"].to_list():\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "    def get_med2(self, t_med2, row):\n",
        "        '''\n",
        "        Return 2nd medication data\n",
        "        '''\n",
        "        temp = t_med2[t_med2[\"HADM_ID\"]==row[\"HADM_ID\"]] \n",
        "        return temp[temp[\"ITEMID\"]==row[\"ITEMID\"]].iloc[0]\n",
        "    \n",
        "    def get_vals(self, r, t_labs, t_med1, t_med2, before_windows, after_windows):\n",
        "        \"\"\"\n",
        "        Calculate the lab test values in time windows before and after medication administration. Return a dataframe with labtest values of before and after windows as a dict\n",
        "        Params: \n",
        "        - before_windows: list of tuples (each tuple is a window)\n",
        "        - after_windows: list of tuples (each tuple is a window)\n",
        "        \"\"\"\n",
        "\n",
        "        row = r.copy()\n",
        "        for b_w in before_windows:\n",
        "            lab_vals = t_labs[t_labs[\"HADM_ID\"]==row[\"HADM_ID\"]]\n",
        "            lab_vals = lab_vals[lab_vals[\"LabTimeFromAdmit\"].dt.total_seconds()<row[\"MedTimeFromAdmit\"].total_seconds()]\n",
        "\n",
        "            b_window_start = row[\"MedTimeFromAdmit\"].total_seconds() - (b_w[0]*3600)\n",
        "            b_window_end = row[\"MedTimeFromAdmit\"].total_seconds() - (b_w[1])*3600\n",
        "            lab_vals = lab_vals[lab_vals[\"LabTimeFromAdmit\"].dt.total_seconds()<b_window_start]\n",
        "            lab_vals = lab_vals[lab_vals[\"LabTimeFromAdmit\"].dt.total_seconds()>b_window_end]\n",
        "            lab_vals[\"hours_from_med\"] = (row[\"STARTTIME\"]-lab_vals[\"CHARTTIME\"]).dt.total_seconds()/3600\n",
        "            lab_vals = lab_vals.sort_values([\"ITEMID\", \"hours_from_med\"])\n",
        "\n",
        "            t = lab_vals.groupby([\"ITEMID\"]).count()[[\"HADM_ID\"]]\n",
        "            val_counts_m = t[t[\"HADM_ID\"]>=1]\n",
        "            if val_counts_m.shape[0]==0:\n",
        "                row[f\"before_abs_{b_w}\"] = {}\n",
        "                row[f\"before_mean_{b_w}\"] = {}\n",
        "                row[f\"before_trends_{b_w}\"] = {}\n",
        "                row[f\"before_time_{b_w}\"] = {}\n",
        "            else:\n",
        "                l_m = lab_vals[lab_vals.ITEMID.isin(val_counts_m.index)]\n",
        "                row[f\"before_abs_{b_w}\"] = l_m.groupby([\"ITEMID\"])[[\"VALUENUM\", \"hours_from_med\"]].first()[\"VALUENUM\"].dropna().to_dict()\n",
        "                row[f\"before_mean_{b_w}\"] = l_m.groupby([\"ITEMID\"])[[\"VALUENUM\"]].mean()[\"VALUENUM\"].dropna().to_dict()\n",
        "                row[f\"before_trends_{b_w}\"] = l_m[[\"VALUENUM\", \"hours_from_med\", \"ITEMID\"]].dropna().groupby([\"ITEMID\"])[[\"VALUENUM\", \"hours_from_med\"]].apply(lambda r : get_normalized_trend(r)).dropna().to_dict()\n",
        "                row[f\"before_time_{b_w}\"] = l_m.groupby([\"ITEMID\"])[[\"VALUENUM\", \"hours_from_med\"]].first()[\"hours_from_med\"].dropna().to_dict()\n",
        "\n",
        "        for a_w in after_windows:\n",
        "\n",
        "            lab_vals = t_labs[t_labs[\"HADM_ID\"]==row[\"HADM_ID\"]]\n",
        "            med2_bool = self.check_med2(t_med2, row)\n",
        "            lab_vals = lab_vals[lab_vals[\"LabTimeFromAdmit\"].dt.total_seconds()>row[\"MedTimeFromAdmit\"].total_seconds()]\n",
        "            a_window_start = row[\"MedTimeFromAdmit\"].total_seconds() + (a_w[0]*3600)\n",
        "            a_window_end = row[\"MedTimeFromAdmit\"].total_seconds() + (a_w[1])*3600\n",
        "            lab_vals = lab_vals[lab_vals[\"LabTimeFromAdmit\"].dt.total_seconds()>a_window_start]\n",
        "            lab_vals = lab_vals[lab_vals[\"LabTimeFromAdmit\"].dt.total_seconds()<a_window_end]\n",
        "            lab_vals[\"hours_from_med\"] = (lab_vals[\"CHARTTIME\"]-row[\"ENDTIME\"]).dt.total_seconds()/3600\n",
        "            lab_vals = lab_vals.sort_values([\"ITEMID\", \"hours_from_med\"])\n",
        "\n",
        "            if med2_bool:\n",
        "                med2_val = self.get_med2(t_med2, row)\n",
        "                lab_vals = lab_vals[lab_vals[\"LabTimeFromAdmit\"].dt.total_seconds()<med2_val[\"MedTimeFromAdmit\"].total_seconds()]\n",
        "            \n",
        "            t = lab_vals.groupby([\"ITEMID\"]).count()[[\"HADM_ID\"]]\n",
        "            \n",
        "            val_counts_m = t[t[\"HADM_ID\"]>=1]\n",
        "            if val_counts_m.shape[0]==0:\n",
        "                row[f\"after_abs_{a_w}\"] = {}\n",
        "                row[f\"after_mean_{a_w}\"] = {}\n",
        "                row[f\"after_trends_{a_w}\"] = {}\n",
        "                row[f\"after_time_{a_w}\"] = {}\n",
        "            else:\n",
        "                l_m = lab_vals[lab_vals.ITEMID.isin(val_counts_m.index)]\n",
        "                row[f\"after_abs_{a_w}\"] = l_m.groupby([\"ITEMID\"])[[\"VALUENUM\", \"hours_from_med\"]].first()[\"VALUENUM\"].dropna().to_dict()\n",
        "                row[f\"after_mean_{a_w}\"] = l_m.groupby([\"ITEMID\"])[[\"VALUENUM\"]].mean()[\"VALUENUM\"].dropna().to_dict()\n",
        "                row[f\"after_trends_{b_w}\"] = l_m[[\"VALUENUM\", \"hours_from_med\", \"ITEMID\"]].dropna().groupby([\"ITEMID\"])[[\"VALUENUM\", \"hours_from_med\"]].apply(lambda r : get_normalized_trend(r)).dropna().to_dict()\n",
        "                row[f\"after_time_{a_w}\"] = l_m.groupby([\"ITEMID\"])[[\"VALUENUM\", \"hours_from_med\"]].first()[\"hours_from_med\"].dropna().to_dict()\n",
        "                \n",
        "        return row\n",
        "    \n",
        "    def generate_med_lab_data(self, t_labs, t_med1, t_med2, before_windows, after_windows):\n",
        "        \"\"\"\n",
        "        Generate lab test values in before and after windows of medication\n",
        "        \"\"\"\n",
        "        \n",
        "        all_types = set([\"abs\", \"time\"])\n",
        "        cols_b = [f\"before_{t}_{b_w}\" for b_w in before_windows for t in all_types]\n",
        "        cols_a = [f\"after_{t}_{a_w}\" for a_w in after_windows for t in all_types]\n",
        "        cols = cols_b.copy()\n",
        "        cols.extend(cols_a)\n",
        "        temp = t_med1.copy()\n",
        "\n",
        "        temp = temp.apply(lambda r : self.get_vals(r, t_labs, t_med1, t_med2, before_windows, after_windows), axis=1)\n",
        "        self.temp = temp\n",
        "        temp.to_csv(os.path.join(self.data, \"mimiciii/1.4/preprocessed\", f\"before_after_windows_main_med_lab_first_val_{self.stratify_prefix}_doc_eval_new_win.csv\"))\n",
        "        \n",
        "        col_vals = []\n",
        "        for col in cols:\n",
        "            col_vals.append(\n",
        "                temp.assign(dict=temp[col].map(lambda d: d.items())).explode(\"dict\", ignore_index=True).assign(\n",
        "                    LAB_ITEMID=lambda df: df.dict.str.get(0),\n",
        "                    temp=lambda df: df.dict.str.get(1)\n",
        "                ).drop(columns=[\"dict\"]+cols).astype({'temp':'float64'}).rename(columns={\"temp\":f\"{col}_sp\"}).dropna(subset=[\"LAB_ITEMID\"])\n",
        "            )\n",
        "        for i in range(1, len(col_vals)):\n",
        "            col_vals[i] = pd.merge(col_vals[i-1], col_vals[i], how=\"outer\", on=list(t_med1.columns)+[\"LAB_ITEMID\"])\n",
        "        \n",
        "        final = col_vals[-1][list(t_med1.columns)+[\"LAB_ITEMID\"]+[f\"{col}_sp\" for col in cols]]\n",
        "        final[\"LAB_NAME\"] = final[\"LAB_ITEMID\"]\n",
        "        final = final.rename(columns={\"ITEMID\":\"MED_NAME\"})\n",
        "        self.final = final\n",
        "        \n",
        "        final.to_csv(os.path.join(self.data, \"mimiciii/1.4/preprocessed\", f\"before_after_windows_main_med_lab_trends_first_val_{self.stratify_prefix}_doc_eval_win.csv\"))\n",
        "\n",
        "        return final, temp\n",
        "    \n",
        "    def query(self):\n",
        "        \"\"\"\n",
        "        Query lab test value for a given medication\n",
        "        \"\"\"\n",
        "        pass\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ClinicalDiscoveryAnalysis(AnalysisUtils):\n",
        "    def __init__(self):\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "class ClinicalPlotAnalysis(AnalysisUtils):\n",
        "\n",
        "    def __init__(self, data, res, gender=\"MF\", age_b=0, age_a=100, ethnicity=\"WHITE\", lab_mapping=None):\n",
        "       super().__init__(data, res, gender=gender, age_b=age_b, age_a=age_a, ethnicity=ethnicity, lab_mapping=lab_mapping)\n",
        "    \n",
        "    def make_plot_dirs(self):\n",
        "        \"\"\"\n",
        "        Create folders to store output plots\n",
        "        \"\"\"\n",
        "        plot_dir = os.path.join(self.res, f\"plots_{self.stratify_prefix}_doc_eval\")\n",
        "        if not os.path.isdir(plot_dir):\n",
        "            os.mkdir(plot_dir)\n",
        "        plot_dir1 = os.path.join(self.res, f\"plots_{self.stratify_prefix}_doc_eval_all_window\")\n",
        "        if not os.path.isdir(plot_dir1):\n",
        "            os.mkdir(plot_dir1)\n",
        "        return plot_dir, plot_dir1\n",
        "    \n",
        "    def generate_plot_data(self, final, before_windows, after_windows):\n",
        "        \"\"\"\n",
        "        Generate plot data for each before and after window\n",
        "        \"\"\"\n",
        "        t_final = final.copy()\n",
        "        plot_data = {}\n",
        "\n",
        "        # generate column names\n",
        "        all_types = set([\"abs\", \"time\"])\n",
        "        cols_b = [f\"before_{t}_{b_w}\" for b_w in before_windows for t in all_types]\n",
        "        cols_a = [f\"after_{t}_{a_w}\" for a_w in after_windows for t in all_types]\n",
        "        \n",
        "        # get data for each before and after window\n",
        "        for b in [f\"{c}_sp\" for c in cols_b]:\n",
        "            if b in t_final.columns:\n",
        "                plot_data[b] = []\n",
        "                for a in [f\"{c}_sp\" for c in cols_a]:\n",
        "                    if a in t_final.columns:\n",
        "                        plot_data[b].append(t_final.dropna(subset=[a,b]))\n",
        "        plot_data_concat = {}\n",
        "        for i in plot_data:\n",
        "            plot_data_concat[i] = pd.concat(plot_data[i])\n",
        "\n",
        "        # Generate columns names\n",
        "        a_t = [\"abs\", \"time\"]\n",
        "        cols_b_sp = [(f\"before_{a_t[0]}_{b_w}_sp\", f\"before_{a_t[1]}_{b_w}_sp\") for b_w in before_windows]\n",
        "        cols_a_sp = [(f\"after_{a_t[0]}_{a_w}_sp\", f\"after_{a_t[1]}_{a_w}_sp\") for a_w in after_windows]\n",
        "        cols_sp = cols_b_sp.copy()\n",
        "        cols_sp.extend(cols_a_sp)\n",
        "        \n",
        "        # get data for each before and after window\n",
        "        t_final = final.copy()\n",
        "        plot_data = {}\n",
        "        for b in cols_b_sp:\n",
        "            if b[0] in t_final.columns:\n",
        "                plot_data[b[0]] = {}\n",
        "                for a in cols_a_sp: \n",
        "                    if a[0] in t_final.columns:\n",
        "                        plot_data[b[0]][a[0]] = t_final.dropna(subset=[a[0], a[1], b[0], b[1]])\n",
        "        pickle.dump(plot_data, open(f\"plot_bw_aw_med_lab_data_{self.stratify_prefix}_doc_eval_win.pkl\", \"wb\"))\n",
        "        \n",
        "        # get data for each medication<>labtest pair\n",
        "        cols_d = dict(cols_sp)\n",
        "        p_data = {}\n",
        "        for k in plot_data:\n",
        "            for i, (k_a, data) in enumerate(plot_data[k].items()):\n",
        "                \n",
        "                t_data = data.set_index([data[\"MED_NAME\"], data[\"LAB_NAME\"]])        \n",
        "                med_lab_pairs = t_data.index\n",
        "                \n",
        "                for med_lab_pair in med_lab_pairs.unique():\n",
        "                    \n",
        "                    if med_lab_pair not in p_data.keys():\n",
        "                        p_data[med_lab_pair] = {}\n",
        "                    if k not in p_data[med_lab_pair].keys():\n",
        "                        p_data[med_lab_pair][k] = []\n",
        "                    \n",
        "                    t_d = t_data.loc[med_lab_pair][['SUBJECT_ID','HADM_ID', k, k_a, cols_d[k_a]]]\n",
        "                    t_d['abs'] = t_d[k_a]-t_d[k]\n",
        "                    t_d['percent'] = (t_d['abs']/t_d[k])*100\n",
        "                    t_d['ratio'] = t_d[k_a]/t_d[k]\n",
        "                    t_d.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "                    t_d = t_d.dropna()\n",
        "                    p_data[med_lab_pair][k].append(t_d)\n",
        "\n",
        "        pickle.dump(p_data, open(f\"plot_med_lab_bw_aw_data_{self.stratify_prefix}_doc_eval_win.pkl\", \"wb\"))\n",
        "        return p_data\n",
        "        \n",
        "\n",
        "    def plot(self, final, t_labs, before_windows, after_windows):\n",
        "        \"\"\"\n",
        "        Plots the correlation and trend plots for before and after windows. Returns a data frame with medication labtest pairs and change over time.\n",
        "        Three different type of plots:\n",
        "        1. Correlation plot (across all after windows for a before window) - plots_corr\n",
        "        2. Large trend/data plot (across all after windows for a before window) - plot_func (type 1)\n",
        "        3. Smaller trend/data plots (for each after window and before window) - plot_func (type 2)\n",
        "        \"\"\"\n",
        "\n",
        "        plot_dir, plot_dir1 = self.make_plot_dirs()\n",
        "        type_map = {\n",
        "            'abs': \"Absolute\",\n",
        "            'percent': \"Percentage\",\n",
        "            'ratio': \"Ratio\"\n",
        "        }\n",
        "\n",
        "        med_vals_new, labtest_vals_new = self.generate_med_lab_pairs()\n",
        "\n",
        "        lab_units_mapping = t_labs.groupby([\"ITEMID\", \"VALUEUOM\"]).count()[\"SUBJECT_ID\"].reset_index().groupby(\"ITEMID\").nth(0)[[\"VALUEUOM\"]]\n",
        "        lab_units_mapping_dict = lab_units_mapping.to_dict()['VALUEUOM']\n",
        "\n",
        "        p_data = self.generate_plot_data(final, before_windows, after_windows)\n",
        "        \n",
        "        n_p_data = {}\n",
        "        if len([i for i in zip(med_vals_new, labtest_vals_new)]) < len(p_data):\n",
        "            for k in [i for i in zip(med_vals_new, labtest_vals_new)]:\n",
        "                if k in p_data:\n",
        "                    n_p_data[k] = p_data[k]\n",
        "        old_p_data = p_data.copy()\n",
        "        p_data = n_p_data\n",
        "\n",
        "        before_windows_map = {f\"({str(b_w)[1:-1]})\":b_w for b_w in before_windows}\n",
        "        after_windows_map = {f\"({str(a_w)[1:-1]})\":a_w for a_w in after_windows}\n",
        "        \n",
        "        # For each medication and lab test pair plot before and after window correlations and trends\n",
        "        types = ['abs', 'percent', 'ratio']\n",
        "        type2 = \"\"\n",
        "        stratify_prefix = self.stratify_prefix\n",
        "        corrs_data_dict = []\n",
        "        for k, v in p_data.items():\n",
        "            for key in v:\n",
        "                if \"/\" in k[0]:\n",
        "                    presc = k[0].split(\"/\")[0]\n",
        "                else:\n",
        "                    presc = k[0]\n",
        "                lab = k[1]\n",
        "                before_window = before_windows_map[key.split(\"_\")[-2]]\n",
        "\n",
        "                fig_all, ax_all = plt.subplots(3, figsize=(20, 20))\n",
        "                fig_all.suptitle(f'{lab}<>{presc} (before window = {str(before_window)})')\n",
        "\n",
        "                if not os.path.isdir(os.path.join(plot_dir, f\"{lab}<>{presc}\")):\n",
        "                    os.mkdir(os.path.join(plot_dir, f\"{lab}<>{presc}\"))\n",
        "                \n",
        "                dirname=f\"bw_{before_window}\"\n",
        "                if not os.path.isdir(os.path.join(plot_dir, f\"{lab}<>{presc}\", dirname)):\n",
        "                    os.mkdir(os.path.join(plot_dir, f\"{lab}<>{presc}\", dirname))\n",
        "                \n",
        "                #  Iterating over the typw of analysis : [\"Absolute\", \"Percentage\", \"Ratio\"]\n",
        "                for i, type1 in enumerate(types):\n",
        "                    \n",
        "                    # Get data type2, remove outliers and calculate correlation\n",
        "                    plot_name = f\"{lab}<>{presc}_{key}_{type1}\"\n",
        "                    data_vals = [d[[list(d.columns)[-4], type1]].rename(columns={list(d.columns)[-4] : \"time\"}) for d in v[key] if type(d) != pd.Series]\n",
        "                    after_names = [list(d.columns)[3] for d in v[key] if type(d) != pd.Series]\n",
        "                    type2 = type1\n",
        "                    if len(data_vals)!=len(after_names):\n",
        "                        print(data_vals)\n",
        "                        print(after_names)\n",
        "                        print()\n",
        "                        continue\n",
        "                    if len(data_vals)==0:\n",
        "                        continue\n",
        "                    d = pd.concat(data_vals)\n",
        "                    if d.shape[0]<2:\n",
        "                        continue\n",
        "                    if d.shape[0]>1:\n",
        "                        d1, d2 = remove_outlier(d[type2], d[\"time\"])\n",
        "                    else:\n",
        "                        d1, d2 = d[[type2]], d[[\"time\"]]\n",
        "                    d = pd.concat([d1, d2], axis=1)\n",
        "\n",
        "                    #  Calculate correlation ovver all after windows\n",
        "                    p_corr = pearsonr(d1[type2], d2[\"time\"])\n",
        "                    s_corr = spearmanr(d1[type2], d2[\"time\"])\n",
        "\n",
        "                    # Get units for the plot and plot overall data plot\n",
        "                    unit = lab_units_mapping_dict[lab] if lab in lab_units_mapping_dict else \"\"\n",
        "                    plot_func(lab, presc, d[[type2, \"time\"]].rename(columns={type2:\"data\"}), dirname=\"\", labels=(p_corr, s_corr), plot_dir=plot_dir, plot_dir1=plot_dir1, unit=unit, title=f\"bw{before_window} {type_map[type2]}\", plot_name=f\"{plot_name}\", ax=ax_all[i])\n",
        "\n",
        "                    # Correlation plots \n",
        "                    fig_corrs, ax_corrs = plt.subplots(2, figsize=(20, 20))\n",
        "                    fig_corrs.suptitle(f'{lab}<>{presc} {type2} corrs') \n",
        "                    corrs = []\n",
        "                    data_t = []\n",
        "                    temp_after_names = after_names.copy()\n",
        "                    for i, d in enumerate(data_vals):\n",
        "                        if d.shape[0]<2:\n",
        "                            temp_after_names.remove(after_names[i])\n",
        "                            continue\n",
        "                        if d.shape[0]>1:\n",
        "                            d1, d2 = remove_outlier(d[type2], d[\"time\"])\n",
        "                        else:\n",
        "                            d1, d2 = d[[type2]], d[[\"time\"]]\n",
        "                        p_corr = pearsonr(d1[type2], d2[\"time\"])\n",
        "                        s_corr = spearmanr(d1[type2], d2[\"time\"])\n",
        "                        corrs.append((p_corr, s_corr))\n",
        "                        data_t.append([d1, d2])\n",
        "                    after_names = temp_after_names\n",
        "                    plot_corrs(corrs, after_names, after_windows_map, ax_corrs, title=type2, plot_name=plot_name)\n",
        "                    \n",
        "                    # Make correlation plot with all windows\n",
        "                    fig_corrs.savefig(os.path.join(plot_dir, f\"{lab}<>{presc}\", dirname, f\"{plot_name}_{type2}_{stratify_prefix}_corrs.png\"))\n",
        "                    fig_corrs.clf()\n",
        "\n",
        "                    for d, a, c, t in zip(data_vals, after_names, corrs, data_t):\n",
        "                        d = pd.concat(t, axis=1)\n",
        "                        p_corr = c[0]\n",
        "                        s_corr = c[1]\n",
        "                        after_window = after_windows_map[a.split(\"_\")[-2]]\n",
        "\n",
        "                        # Make plot with data points in a single window\n",
        "                        plot_func(lab, presc, d[[type2, \"time\"]].rename(columns={type2:\"data\"}), dirname=dirname, plot_dir=plot_dir, plot_dir1=plot_dir1, labels=c, unit=unit, title=f\"bw{before_window} aw{after_window} {type_map[type2]}\", plot_name=f\"{plot_name} bw{before_window} aw{after_window}\")\n",
        "                        corrs_data_dict.append({\n",
        "                            \"lab\" : lab,\n",
        "                            \"med\": presc,\n",
        "                            \"bw\": before_window,\n",
        "                            \"aw\": after_window,\n",
        "                            \"Type\": type_map[type2],\n",
        "                            \"Pearson Correlation\": p_corr[0],\n",
        "                            \"Pearson Correlation (p-value)\": p_corr[1],\n",
        "                            \"Spearmans Correlation \": s_corr[0],\n",
        "                            \"Spearmans Correlation (p-value)\": s_corr[1],\n",
        "                            \"Num of Data Points (n)\": d.shape[0]\n",
        "                        })\n",
        "\n",
        "                fig_all.savefig(os.path.join(plot_dir, f\"{lab}<>{presc}\", dirname, f\"{plot_name}_{stratify_prefix}.png\"))\n",
        "                fig_all.clf()\n",
        "        \n",
        "        # Save correlation values for each type, after and before window\n",
        "        corrs_data_df = pd.DataFrame(corrs_data_dict)\n",
        "        corrs_data_df.to_csv(os.path.join(plot_dir, f\"corrs_data_{stratify_prefix}.csv\"))\n",
        "        return corrs_data_df\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "GvgqODe6z9Qk"
      },
      "source": [
        "## Setup Config"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Vl4E0-D8z7Fb"
      },
      "source": [
        "### Input - Output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "9RmYNE2AtGRE"
      },
      "outputs": [],
      "source": [
        "# Input - Output config\n",
        "#  Add your own drive paths\n",
        "\n",
        "# MIMIC\n",
        "# data = \"/gdrive/MyDrive/TAU/Code/DrugLab/data\"\n",
        "# res = \"/gdrive/MyDrive/TAU/Code/DrugLab/results\"\n",
        "data = \"/Volumes/GoogleDrive/My Drive/TAU/Code/DrugLab/data\"\n",
        "res = \"/Volumes/GoogleDrive/My Drive/TAU/Code/DrugLab/results\"\n",
        "\n",
        "# HIRID\n",
        "# raw_path = '/gdrive/MyDrive/TAU/Code/DrugLab/data/hirid-a-high-time-resolution-icu-dataset-1.1.1/raw_stage/'\n",
        "# res_path = '/gdrive/MyDrive/TAU/Code/DrugLab/data/hirid-a-high-time-resolution-icu-dataset-1.1.1'\n",
        "raw_path = '/Volumes/GoogleDrive/My Drive/TAU/Code/DrugLab/data/hirid-a-high-time-resolution-icu-dataset-1.1.1/raw_stage/'\n",
        "res_path = '/Volumes/GoogleDrive/My Drive/TAU/Code/DrugLab/data/hirid-a-high-time-resolution-icu-dataset-1.1.1'"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ggL_PZOL0ABJ"
      },
      "source": [
        "### Stratification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "zhavl0JEzyRl"
      },
      "outputs": [],
      "source": [
        "# Stratification Config\n",
        "gender=\"MF\"\n",
        "age_b=40\n",
        "age_a=80 \n",
        "ethnicity=\"WHITE\" "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "OatepD9YnfnC"
      },
      "outputs": [],
      "source": [
        "lab_mapping=lab_mapping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "before_windows = [(0,12), (0,6)]\n",
        "after_windows = [(0,1), (1,2), (2,3), (3,4), (4,5), (5,6), (6,7), (7,8), (8,9), (9,10), (10,11), (11,12)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## MIMIC"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### MIMIC Parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mimic_parser = MIMICParser(data=data, res=res, gender=gender, age_b=age_b, age_a=age_a, ethnicity=ethnicity, lab_mapping=lab_mapping)\n",
        "m_med1, m_med2, m_labs = mimic_parser.parse()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srC6b9AEtXi0"
      },
      "source": [
        "### Query Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_EZq2HHLfbtx"
      },
      "outputs": [],
      "source": [
        "mimic_data_querier = DatasetQuerier(\n",
        "    data = data,\n",
        "    res = res,\n",
        "    gender=gender, \n",
        "    age_b=age_b, \n",
        "    age_a=age_a, \n",
        "    ethnicity=ethnicity, \n",
        "    lab_mapping=lab_mapping\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mF4B6wjCktED"
      },
      "outputs": [],
      "source": [
        "m_final_lab_med_data = mimic_data_querier.generate_med_lab_data(m_labs, m_med1, m_med2, before_windows, after_windows)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Discovery Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iG7kOj3xtlfy"
      },
      "source": [
        "### Plot Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nqAKOJH6h-Pq"
      },
      "outputs": [],
      "source": [
        "plotter = ClinicalPlotAnalysis(\n",
        "    data = data,\n",
        "    res = res,\n",
        "    gender=gender, \n",
        "    age_b=age_b, \n",
        "    age_a=age_a, \n",
        "    ethnicity=ethnicity, \n",
        "    lab_mapping=lab_mapping\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fNOd5R4NovYX"
      },
      "outputs": [],
      "source": [
        "m_corrs_data_df = plotter.plot(m_final_lab_med_data, m_labs, before_windows=before_windows, after_windows=after_windows)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## HIRID"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### HiRiD Parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "hirid_parser = HiRiDParser(data=raw_path, res=res_path, gender=gender, age_b=age_b, age_a=age_a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/xb/6svjl9sj43z6gfhlcp2nc5540000gr/T/ipykernel_92073/3202575334.py:78: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  labs = pd.read_csv(path)\n",
            "/var/folders/xb/6svjl9sj43z6gfhlcp2nc5540000gr/T/ipykernel_92073/3202575334.py:78: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  labs = pd.read_csv(path)\n",
            "/var/folders/xb/6svjl9sj43z6gfhlcp2nc5540000gr/T/ipykernel_92073/3202575334.py:78: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  labs = pd.read_csv(path)\n",
            "/var/folders/xb/6svjl9sj43z6gfhlcp2nc5540000gr/T/ipykernel_92073/3202575334.py:78: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  labs = pd.read_csv(path)\n",
            "/var/folders/xb/6svjl9sj43z6gfhlcp2nc5540000gr/T/ipykernel_92073/3202575334.py:78: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  labs = pd.read_csv(path)\n",
            "/var/folders/xb/6svjl9sj43z6gfhlcp2nc5540000gr/T/ipykernel_92073/3202575334.py:78: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  labs = pd.read_csv(path)\n",
            "/var/folders/xb/6svjl9sj43z6gfhlcp2nc5540000gr/T/ipykernel_92073/3202575334.py:78: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  labs = pd.read_csv(path)\n",
            "/var/folders/xb/6svjl9sj43z6gfhlcp2nc5540000gr/T/ipykernel_92073/3202575334.py:78: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  labs = pd.read_csv(path)\n",
            "/var/folders/xb/6svjl9sj43z6gfhlcp2nc5540000gr/T/ipykernel_92073/3202575334.py:78: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  labs = pd.read_csv(path)\n",
            "/var/folders/xb/6svjl9sj43z6gfhlcp2nc5540000gr/T/ipykernel_92073/3202575334.py:78: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  labs = pd.read_csv(path)\n",
            "/var/folders/xb/6svjl9sj43z6gfhlcp2nc5540000gr/T/ipykernel_92073/3202575334.py:78: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  labs = pd.read_csv(path)\n",
            "/var/folders/xb/6svjl9sj43z6gfhlcp2nc5540000gr/T/ipykernel_92073/3202575334.py:78: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  labs = pd.read_csv(path)\n",
            "/var/folders/xb/6svjl9sj43z6gfhlcp2nc5540000gr/T/ipykernel_92073/3202575334.py:78: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  labs = pd.read_csv(path)\n",
            "/var/folders/xb/6svjl9sj43z6gfhlcp2nc5540000gr/T/ipykernel_92073/3202575334.py:78: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  labs = pd.read_csv(path)\n",
            "/var/folders/xb/6svjl9sj43z6gfhlcp2nc5540000gr/T/ipykernel_92073/3202575334.py:78: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  labs = pd.read_csv(path)\n",
            "/var/folders/xb/6svjl9sj43z6gfhlcp2nc5540000gr/T/ipykernel_92073/3202575334.py:78: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  labs = pd.read_csv(path)\n",
            "/var/folders/xb/6svjl9sj43z6gfhlcp2nc5540000gr/T/ipykernel_92073/3202575334.py:78: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  labs = pd.read_csv(path)\n",
            "/var/folders/xb/6svjl9sj43z6gfhlcp2nc5540000gr/T/ipykernel_92073/3202575334.py:78: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  labs = pd.read_csv(path)\n",
            "/var/folders/xb/6svjl9sj43z6gfhlcp2nc5540000gr/T/ipykernel_92073/3202575334.py:78: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  labs = pd.read_csv(path)\n",
            "/var/folders/xb/6svjl9sj43z6gfhlcp2nc5540000gr/T/ipykernel_92073/3202575334.py:78: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  labs = pd.read_csv(path)\n",
            "/var/folders/xb/6svjl9sj43z6gfhlcp2nc5540000gr/T/ipykernel_92073/3202575334.py:78: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  labs = pd.read_csv(path)\n",
            "/var/folders/xb/6svjl9sj43z6gfhlcp2nc5540000gr/T/ipykernel_92073/3202575334.py:78: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  labs = pd.read_csv(path)\n",
            "/var/folders/xb/6svjl9sj43z6gfhlcp2nc5540000gr/T/ipykernel_92073/3202575334.py:78: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  labs = pd.read_csv(path)\n",
            "/var/folders/xb/6svjl9sj43z6gfhlcp2nc5540000gr/T/ipykernel_92073/3202575334.py:78: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  labs = pd.read_csv(path)\n",
            "/var/folders/xb/6svjl9sj43z6gfhlcp2nc5540000gr/T/ipykernel_92073/3202575334.py:78: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  labs = pd.read_csv(path)\n",
            "/var/folders/xb/6svjl9sj43z6gfhlcp2nc5540000gr/T/ipykernel_92073/3202575334.py:78: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  labs = pd.read_csv(path)\n",
            "/var/folders/xb/6svjl9sj43z6gfhlcp2nc5540000gr/T/ipykernel_92073/3202575334.py:78: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  labs = pd.read_csv(path)\n",
            "/var/folders/xb/6svjl9sj43z6gfhlcp2nc5540000gr/T/ipykernel_92073/3202575334.py:78: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  labs = pd.read_csv(path)\n",
            "/var/folders/xb/6svjl9sj43z6gfhlcp2nc5540000gr/T/ipykernel_92073/3202575334.py:78: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  labs = pd.read_csv(path)\n",
            "/var/folders/xb/6svjl9sj43z6gfhlcp2nc5540000gr/T/ipykernel_92073/3202575334.py:78: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  labs = pd.read_csv(path)\n",
            "/var/folders/xb/6svjl9sj43z6gfhlcp2nc5540000gr/T/ipykernel_92073/3202575334.py:78: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  labs = pd.read_csv(path)\n",
            "/var/folders/xb/6svjl9sj43z6gfhlcp2nc5540000gr/T/ipykernel_92073/3202575334.py:78: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  labs = pd.read_csv(path)\n",
            "/var/folders/xb/6svjl9sj43z6gfhlcp2nc5540000gr/T/ipykernel_92073/3202575334.py:78: DtypeWarning: Columns (4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  labs = pd.read_csv(path)\n",
            "/var/folders/xb/6svjl9sj43z6gfhlcp2nc5540000gr/T/ipykernel_92073/3202575334.py:78: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  labs = pd.read_csv(path)\n",
            "/var/folders/xb/6svjl9sj43z6gfhlcp2nc5540000gr/T/ipykernel_92073/3202575334.py:78: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  labs = pd.read_csv(path)\n",
            "/var/folders/xb/6svjl9sj43z6gfhlcp2nc5540000gr/T/ipykernel_92073/3202575334.py:78: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  labs = pd.read_csv(path)\n",
            "/var/folders/xb/6svjl9sj43z6gfhlcp2nc5540000gr/T/ipykernel_92073/3202575334.py:78: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  labs = pd.read_csv(path)\n",
            "/var/folders/xb/6svjl9sj43z6gfhlcp2nc5540000gr/T/ipykernel_92073/3202575334.py:78: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  labs = pd.read_csv(path)\n",
            "/var/folders/xb/6svjl9sj43z6gfhlcp2nc5540000gr/T/ipykernel_92073/3202575334.py:78: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  labs = pd.read_csv(path)\n",
            "/var/folders/xb/6svjl9sj43z6gfhlcp2nc5540000gr/T/ipykernel_92073/3202575334.py:78: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  labs = pd.read_csv(path)\n",
            "/var/folders/xb/6svjl9sj43z6gfhlcp2nc5540000gr/T/ipykernel_92073/3202575334.py:78: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  labs = pd.read_csv(path)\n",
            "/var/folders/xb/6svjl9sj43z6gfhlcp2nc5540000gr/T/ipykernel_92073/3202575334.py:78: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  labs = pd.read_csv(path)\n",
            "/var/folders/xb/6svjl9sj43z6gfhlcp2nc5540000gr/T/ipykernel_92073/3202575334.py:78: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  labs = pd.read_csv(path)\n",
            "/var/folders/xb/6svjl9sj43z6gfhlcp2nc5540000gr/T/ipykernel_92073/3202575334.py:78: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  labs = pd.read_csv(path)\n",
            "/var/folders/xb/6svjl9sj43z6gfhlcp2nc5540000gr/T/ipykernel_92073/3202575334.py:78: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  labs = pd.read_csv(path)\n",
            "/var/folders/xb/6svjl9sj43z6gfhlcp2nc5540000gr/T/ipykernel_92073/3202575334.py:78: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  labs = pd.read_csv(path)\n",
            "/var/folders/xb/6svjl9sj43z6gfhlcp2nc5540000gr/T/ipykernel_92073/3202575334.py:78: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  labs = pd.read_csv(path)\n",
            "/var/folders/xb/6svjl9sj43z6gfhlcp2nc5540000gr/T/ipykernel_92073/3202575334.py:78: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  labs = pd.read_csv(path)\n",
            "/var/folders/xb/6svjl9sj43z6gfhlcp2nc5540000gr/T/ipykernel_92073/3202575334.py:78: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  labs = pd.read_csv(path)\n",
            "/var/folders/xb/6svjl9sj43z6gfhlcp2nc5540000gr/T/ipykernel_92073/3202575334.py:78: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  labs = pd.read_csv(path)\n"
          ]
        }
      ],
      "source": [
        "h_med1, h_med2, h_labs = hirid_parser.parse()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srC6b9AEtXi0"
      },
      "source": [
        "### Query Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "_EZq2HHLfbtx"
      },
      "outputs": [],
      "source": [
        "hirid_data_querier = DatasetQuerier(\n",
        "    data = data,\n",
        "    res = res,\n",
        "    gender=gender, \n",
        "    age_b=age_b, \n",
        "    age_a=age_a, \n",
        "    ethnicity=ethnicity, \n",
        "    lab_mapping=lab_mapping\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "mF4B6wjCktED"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mCanceled future for execute_request message before replies were done"
          ]
        }
      ],
      "source": [
        "final_h_final_lab_med_data, raw_h_final_lab_med_data = hirid_data_querier.generate_med_lab_data(h_labs, h_med1, h_med2, before_windows, after_windows)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Discovery Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iG7kOj3xtlfy"
      },
      "source": [
        "### Plot Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nqAKOJH6h-Pq"
      },
      "outputs": [],
      "source": [
        "h_plotter = ClinicalPlotAnalysis(\n",
        "    data = data,\n",
        "    res = res,\n",
        "    gender=gender, \n",
        "    age_b=age_b, \n",
        "    age_a=age_a, \n",
        "    ethnicity=\"\", \n",
        "    lab_mapping={}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fNOd5R4NovYX"
      },
      "outputs": [],
      "source": [
        "h_corrs_data_df = h_plotter.plot(final_h_final_lab_med_data, h_labs, before_windows=before_windows, after_windows=after_windows)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "7r295yf_0FuH",
        "Ee2ApMjC0Jgh",
        "Vl4E0-D8z7Fb",
        "ggL_PZOL0ABJ",
        "srC6b9AEtXi0",
        "iG7kOj3xtlfy"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "drug_lab",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "bdfae57a338f302dc1dcec357ac11e9f753ccc771aa1c4e860bf04580c454473"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
